# ğŸ½ï¸ Open Food Facts API - Laravel Challenge TruckPag

API para importaÃ§Ã£o, armazenamento e gerenciamento de dados alimentÃ­cios com base na base de dados pÃºblica [Open Food Facts](https://br.openfoodfacts.org/data).
This is a challenge by Coodesh
---

## ğŸ“š Sobre o Projeto

Este projeto foi desenvolvido como parte de um desafio tÃ©cnico proposto pela **TruckPag**. Ele consiste em consumir dados do Open Food Facts, armazenÃ¡-los em uma base MongoDB e expÃ´-los via uma API Laravel.

---

## ğŸš€ Tecnologias Utilizadas

### ğŸ§± Back-End

- **Linguagem**: PHP 8.2  
- **Framework**: Laravel 10  
- **Banco de Dados**: MongoDB (MongoDB Atlas)  
- **Gerenciador de DependÃªncias**: Composer  

### ğŸ“¦ Bibliotecas e Pacotes

- [`mongodb/mongodb`](https://github.com/mongodb/mongo-php-library) â€” Driver MongoDB para PHP  
- Laravel HTTP Client (baseado em Guzzle) â€” para requisiÃ§Ãµes aos arquivos `.json.gz`  


### ğŸ› ï¸ Ferramentas

- **Docker** â€” para containerizaÃ§Ã£o do ambiente  
- **Docker Compose** â€” orquestraÃ§Ã£o de serviÃ§os  
- **Supervisor** â€” gerenciamento de mÃºltiplos processos simultÃ¢neos (API, queue worker, scheduler)  
- **Postman** â€” testes manuais da API  
- **Git** â€” versionamento do projeto

## ğŸš€ Como Instalar e Usar o Projeto

VocÃª pode rodar este projeto **com ou sem Docker**. Abaixo estÃ£o as instruÃ§Ãµes para ambos os cenÃ¡rios:

---

### âœ… Rodando **sem Docker**

```bash
# Clone o repositÃ³rio e entre na pasta
git clone https://github.com/josesousacruz/products-parse-truckPag.git
cd food-api-truckpag

# Instale as dependÃªncias
composer install

# Configure o MongoDB no .env

# Em terminais separados, execute:

# Terminal 1 - para rodar o projeto
php artisan serve

# Terminal 2 - para processar a fila
php artisan queue:work

# Terminal 3 - para executar os agendamentos a cada minuto
php artisan schedule:work
```
---

### ğŸ³ Rodando **com Docker**

```bash
# Acesse a pasta docker/
cd docker

# Suba os containers
docker compose up --build -d
```

Esse comando irÃ¡:
- Subir o Laravel com PHP
- Iniciar o servidor embutido
- Executar o scheduler e o queue worker via Supervisor

- 
> â° O comando agendado para importar os arquivos do Open Food Facts roda automaticamente todos os dias Ã s **02:00 da manhÃ£**.
> Ou Execute:
```bash
docker exec -it nome-do-container php artisan import:openfoodfacts
```
## ğŸ§ª Como Executar os Testes

```bash
# Sem Docker
php artisan test

# Com Docker
docker exec -it nome-do-container php artisan test

```

## ğŸ› ï¸ Processo de Desenvolvimento

### DecisÃ£o pelo Banco de Dados  
Considerei utilizar MySQL, pois tenho mais experiÃªncia e utilizo no dia a dia. No entanto, optei por MongoDB, conforme a proposta do desafio, para explorar uma abordagem NoSQL e facilitar o armazenamento dos dados flexÃ­veis do Open Food Facts.

### ConexÃ£o com o Banco de Dados  
O primeiro passo foi garantir a conexÃ£o com o banco de dados MongoDB (via Atlas).  
Com a conexÃ£o testada e validada, inseri manualmente alguns produtos na collection `products` para implementar rotas, controllers, models e migrations:


### LÃ³gica de ImportaÃ§Ã£o  
Inicialmente implementei a importaÃ§Ã£o em um Ãºnico job, mas logo percebi que os arquivos `.json.gz` eram extremamente grandes, o que fazia a aplicaÃ§Ã£o ultrapassar os limites de **tempo de execuÃ§Ã£o** e **memÃ³ria**.


Para contornar isso, refatorei a lÃ³gica para dividir a tarefa em **mÃºltiplos jobs pequenos** (chunks), reduzindo drasticamente o risco de falhas por timeout ou estouro de memÃ³ria.

TambÃ©m utilizei tÃ©cnicas especÃ­ficas para minimizar o uso de memÃ³ria:

- `stream_copy_to_stream()` foi usado para descompactar os arquivos `.gz` diretamente em `.json`, evitando carregar todo o conteÃºdo em memÃ³ria.
- A leitura foi feita linha a linha com `fopen`, `fgets`, `feof` e `fclose`, processando o arquivo em fluxo (stream) em vez de armazenÃ¡-lo inteiro em arrays.

Essas prÃ¡ticas tornaram o processo mais eficiente e compatÃ­vel com ambientes restritos como containers Docker.

AlÃ©m disso, realizei ajustes nos comandos:
- `set_time_limit(0)`
- `ini_set('memory_limit', '2048M')`

### Fila de Processamento  
Utilizei o sistema de **queue do Laravel** com driver `database`, para manter rastreamento e persistÃªncia dos jobs.  
No Docker, configurei o `supervisord` para manter os workers ativos em background, garantindo execuÃ§Ã£o contÃ­nua.

- Os dados sÃ£o processados em **chunks de 100 linhas**, cada um gerando um job separado (`ImportOpenFoodFactsChunkJob`).
- Isso aumentou a escalabilidade e evitou travamentos do container, alÃ©m de permitir reprocessamento seletivo.

### Agendamento de Tarefas  
A rotina de importaÃ§Ã£o Ã© executada diariamente Ã s **2h da manhÃ£** via Laravel Scheduler (`schedule:work`).  

- Em ambiente Docker, o `supervisord` Ã© responsÃ¡vel por manter o processo ativo e rodando a cada minuto.

### ConsideraÃ§Ãµes sobre o Docker  
Implementei uma configuraÃ§Ã£o Docker completa com:

- `Dockerfile`  
- `docker-compose.yml`  
- `supervisord.conf`

Tudo pronto para subir rapidamente o ambiente de desenvolvimento.

> âš ï¸ **ObservaÃ§Ã£o:** Durante os testes, identifiquei que o ambiente Docker possui **limitaÃ§Ãµes de recursos** que podem causar falhas nos jobs de importaÃ§Ã£o (ex: timeout, consumo de memÃ³ria).  
> Esse erro **nÃ£o ocorre** ao rodar o projeto diretamente fora do container.  
> NÃ£o tive tempo hÃ¡bil para resolver essa limitaÃ§Ã£o no ambiente Docker.

