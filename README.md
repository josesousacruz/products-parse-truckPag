# üçΩÔ∏è Open Food Facts API - Laravel Challenge TruckPag

API para importa√ß√£o, armazenamento e gerenciamento de dados aliment√≠cios com base na base de dados p√∫blica [Open Food Facts](https://br.openfoodfacts.org/data).
---
This is a challenge by Coodesh


## üìö Sobre o Projeto

Este projeto foi desenvolvido como parte de um desafio t√©cnico proposto pela **TruckPag**. Ele consiste em consumir dados do Open Food Facts, armazen√°-los em uma base MongoDB e exp√¥-los via uma API Laravel.

---
## üìÑ Documenta√ß√£o da API

A documenta√ß√£o da API est√° dispon√≠vel via Swagger UI:

üîó **[Clique aqui para acessar a documenta√ß√£o](http://localhost:8000/api/documentation)**
**A aplica√ß√£o precisa estar rodando para acessar a documenta√ß√£o**

## üöÄ Tecnologias Utilizadas

### üß± Back-End

- **Linguagem**: PHP 8.2  
- **Framework**: Laravel 10  
- **Banco de Dados**: MongoDB (MongoDB Atlas)  
- **Gerenciador de Depend√™ncias**: Composer  

### üì¶ Bibliotecas e Pacotes

- [`mongodb/mongodb`](https://github.com/mongodb/mongo-php-library) ‚Äî Driver MongoDB para PHP  
- Laravel HTTP Client (baseado em Guzzle) ‚Äî para requisi√ß√µes aos arquivos `.json.gz`  


### üõ†Ô∏è Ferramentas

- **Docker** ‚Äî para containeriza√ß√£o do ambiente  
- **Docker Compose** ‚Äî orquestra√ß√£o de servi√ßos  
- **Supervisor** ‚Äî gerenciamento de m√∫ltiplos processos simult√¢neos (API, queue worker, scheduler)  
- **Postman** ‚Äî testes manuais da API  
- **Git** ‚Äî versionamento do projeto

## üöÄ Como Instalar e Usar o Projeto

Voc√™ pode rodar este projeto **com ou sem Docker**. Abaixo est√£o as instru√ß√µes para ambos os cen√°rios:

---

### ‚úÖ Rodando **sem Docker**

```bash
# Clone o reposit√≥rio e entre na pasta
git clone https://github.com/josesousacruz/products-parse-truckPag.git
cd food-api-truckpag

# Instale as depend√™ncias
composer install

# Configure o MongoDB no .env

# Em terminais separados, execute:

# Terminal 1 - para rodar o projeto
php artisan serve

# Terminal 2 - para processar a fila
php artisan queue:work

# Terminal 3 - para executar os agendamentos a cada minuto
php artisan schedule:work
```
---

### üê≥ Rodando **com Docker**

```bash
# Acesse a pasta docker/
cd docker

# Suba os containers
docker compose up --build -d
```

Esse comando ir√°:
- Subir o Laravel com PHP
- Iniciar o servidor embutido
- Executar o scheduler e o queue worker via Supervisor

- 
> ‚è∞ O comando agendado para importar os arquivos do Open Food Facts roda automaticamente todos os dias √†s **02:00 da manh√£**.
> Ou Execute:
```bash
docker exec -it nome-do-container php artisan import:openfoodfacts
```
## üß™ Como Executar os Testes

```bash
# Sem Docker
php artisan test

# Com Docker
docker exec -it nome-do-container php artisan test

```

## üõ†Ô∏è Processo de Desenvolvimento

### Decis√£o pelo Banco de Dados  
Considerei utilizar MySQL, pois tenho mais experi√™ncia e utilizo no dia a dia. No entanto, optei por MongoDB, conforme a proposta do desafio, para explorar uma abordagem NoSQL e facilitar o armazenamento dos dados flex√≠veis do Open Food Facts.

### Conex√£o com o Banco de Dados  
O primeiro passo foi garantir a conex√£o com o banco de dados MongoDB (via Atlas).  
Com a conex√£o testada e validada, inseri manualmente alguns produtos na collection `products` para implementar rotas, controllers, models e migrations:


### L√≥gica de Importa√ß√£o  
Inicialmente implementei a importa√ß√£o em um √∫nico job, mas logo percebi que os arquivos `.json.gz` eram extremamente grandes, o que fazia a aplica√ß√£o ultrapassar os limites de **tempo de execu√ß√£o** e **mem√≥ria**.


Para contornar isso, refatorei a l√≥gica para dividir a tarefa em **m√∫ltiplos jobs pequenos** (chunks), reduzindo drasticamente o risco de falhas por timeout ou estouro de mem√≥ria.

Tamb√©m utilizei t√©cnicas espec√≠ficas para minimizar o uso de mem√≥ria:

- `stream_copy_to_stream()` foi usado para descompactar os arquivos `.gz` diretamente em `.json`, evitando carregar todo o conte√∫do em mem√≥ria.
- A leitura foi feita linha a linha com `fopen`, `fgets`, `feof` e `fclose`, processando o arquivo em fluxo (stream) em vez de armazen√°-lo inteiro em arrays.

Essas pr√°ticas tornaram o processo mais eficiente e compat√≠vel com ambientes restritos como containers Docker.

Al√©m disso, realizei ajustes nos comandos:
- `set_time_limit(0)`
- `ini_set('memory_limit', '2048M')`

### Fila de Processamento  
Utilizei o sistema de **queue do Laravel** com driver `database`, para manter rastreamento e persist√™ncia dos jobs.  
No Docker, configurei o `supervisord` para manter os workers ativos em background, garantindo execu√ß√£o cont√≠nua.

- Os dados s√£o processados em **chunks de 100 linhas**, cada um gerando um job separado (`ImportOpenFoodFactsChunkJob`).
- Isso aumentou a escalabilidade e evitou travamentos do container, al√©m de permitir reprocessamento seletivo.

### Agendamento de Tarefas  
A rotina de importa√ß√£o √© executada diariamente √†s **2h da manh√£** via Laravel Scheduler (`schedule:work`).  

- Em ambiente Docker, o `supervisord` √© respons√°vel por manter o processo ativo e rodando a cada minuto.

### Considera√ß√µes sobre o Docker  
Implementei uma configura√ß√£o Docker completa com:

- `Dockerfile`  
- `docker-compose.yml`  
- `supervisord.conf`

Tudo pronto para subir rapidamente o ambiente de desenvolvimento.

> ‚ö†Ô∏è **Observa√ß√£o:** Durante os testes, identifiquei que o ambiente Docker possui **limita√ß√µes de recursos** que podem causar falhas nos jobs de importa√ß√£o (ex: timeout, consumo de mem√≥ria).  
> Esse erro **n√£o ocorre** ao rodar o projeto diretamente fora do container.  
> N√£o tive tempo h√°bil para resolver essa limita√ß√£o no ambiente Docker.

---

## ‚ö†Ô∏è Pontos N√£o Implementados

Alguns requisitos do desafio foram considerados mas **n√£o implementados integralmente** por motivo de tempo ou escopo:

- ‚ùå **Endpoint de busca com ElasticSearch (ou similar)**  
  > A estrutura inicial para uma busca customizada foi iniciada, mas a integra√ß√£o com ElasticSearch n√£o foi conclu√≠da.

- ‚ùå **Sistema de alerta em caso de falhas no Sync dos produtos**  
  > N√£o implementado. A aplica√ß√£o atualmente realiza o processo de importa√ß√£o com filas e logs, mas sem alertas automatizados.

- ‚ùå **Esquema de seguran√ßa com API Key nos endpoints**  
  > Planejado, por√©m n√£o implementado por falta de tempo h√°bil. A API est√° atualmente aberta para facilitar os testes.

---


